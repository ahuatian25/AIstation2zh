{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验R3:引入LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras import layers,metrics\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU, ELU, ReLU\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.utils import shuffle as reset\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss,make_scorer\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "# import \n",
    "from matplotlib.pylab import plt\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler #https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.RandomOverSampler.html?highlight=randomoversampler\n",
    "from frplayer import FilterResponseNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_DataFrame(data, test_size=0.2, considerTime=True, random_state=None):\n",
    "    # ConsiderTime-------trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "    if considerTime:\n",
    "        data=data.sort_values(by=\"Dates\", ascending=True)\n",
    "    else:\n",
    "        data=reset(data, random_state=random_state)\n",
    "    train=data[int(len(data)*test_size):].reset_index(drop=True)\n",
    "    test=data[:int(len(data)*test_size)].reset_index(drop=True)\n",
    "    return train, test\n",
    "\n",
    "def comparePlusMultResult(scoreDNN,scoreRNN,Y):\n",
    "    scorePrePlus=np.add(scoreDNN,scoreRNN)\n",
    "    scorePreMult=np.multiply(scoreDNN,scoreRNN)\n",
    "    \n",
    "    M=np.nanmax(scorePrePlus)\n",
    "    A=np.where(scorePrePlus == M, 1, scorePrePlus)\n",
    "    Plus_One=np.where(A < 1.0, 0, A)\n",
    "    \n",
    "    M=np.nanmax(scorePreMult)\n",
    "    A=np.where(scorePreMult == M, 1, scorePreMult)\n",
    "    Mult_One=np.where(A < 1.0, 0, A)    \n",
    "    \n",
    "    Plus_Result=0.0\n",
    "    Mult_Result=0.0\n",
    "    if np.sum(np.abs(np.array(Plus_One)-np.array(Y)))==0.0:\n",
    "        Plus_Result=1.0\n",
    "    if np.sum(np.abs(np.array(Mult_One)-np.array(Y)))==0.0:\n",
    "        Plus_Result=1.0\n",
    "    return Plus_Result, Mult_Result\n",
    "\n",
    "def compareResult(scoreNN,Y):\n",
    "    M=np.nanmax(scoreNN)\n",
    "    A=np.where(scoreNN == M, 1, scoreNN)\n",
    "    B=np.where(A < 1.0, 0, A)    \n",
    "    Result=0.0\n",
    "#     print(B)\n",
    "#     print(Y)\n",
    "#     print(np.sum(np.abs(np.array(B)-np.array(Y))))\n",
    "    if np.sum(np.abs(np.array(B)-np.array(Y)))==0.0:\n",
    "        Result=1.0\n",
    "    return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(x):\n",
    "    DD=datetime.strptime(x,\"%Y-%m-%d %H:%M\")#zj    \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    return time,day,month,year\n",
    "def Dates2TDMY(x):\n",
    "    DD=datetime.strptime(x,\"%Y-%m-%d %H:%M\")#zj  \n",
    "    time=DD.hour#*60+DD.minute\n",
    "    day=DD.day\n",
    "    month=DD.month\n",
    "    year=DD.year\n",
    "    #T_D_M_Y=str(time)+str(day)+str(month)+str(year)\n",
    "    T_D_M_Y=str(time)+str(day)+str(month)\n",
    "    return T_D_M_Y\n",
    "def get_season(x):\n",
    "    summer=0\n",
    "    fall=0\n",
    "    winter=0\n",
    "    spring=0\n",
    "    if (x in [5, 6, 7]):\n",
    "        summer=1\n",
    "    if (x in [8, 9, 10]):\n",
    "        fall=1\n",
    "    if (x in [11, 0, 1]):\n",
    "        winter=1\n",
    "    if (x in [2, 3, 4]):\n",
    "        spring=1\n",
    "    return summer, fall, winter, spring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field2Vec(trainDF,testDF,fieldStr):\n",
    "    fields=sorted(trainDF[fieldStr].unique())\n",
    "    categories=sorted(trainDF[\"Category\"].unique())\n",
    "    C_counts=trainDF.groupby([\"Category\"]).size()\n",
    "    F_C_counts=trainDF.groupby([fieldStr,\"Category\"]).size()\n",
    "    F_counts=trainDF.groupby([fieldStr]).size()\n",
    "    logodds={}\n",
    "    logoddsPF={}\n",
    "    MIN_CAT_COUNTS=2\n",
    "    default_logodds=np.log(C_counts/len(trainDF))-np.log(1.0-C_counts/float(len(trainDF)))\n",
    "    for f in fields:\n",
    "        PA=F_counts[f]/float(len(trainDF))\n",
    "        logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "        logodds[f]=deepcopy(default_logodds)\n",
    "        for cat in F_C_counts[f].keys():\n",
    "            if (F_C_counts[f][cat]>MIN_CAT_COUNTS) and F_C_counts[f][cat]<F_counts[f]:\n",
    "                PA=F_C_counts[f][cat]/float(F_counts[f])\n",
    "                logodds[f][categories.index(cat)]=np.log(PA)-np.log(1.0-PA)\n",
    "        logodds[f]=pd.Series(logodds[f])\n",
    "        logodds[f].index=range(len(categories))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #fieldsTest=sorted(testDF[fieldStr].unique())\n",
    "    #N_count=0\n",
    "    #for f in fieldsTest:\n",
    "        #if f not in fields:\n",
    "            #logoddsPF[f]=-50.0  #np.log(0.)-np.log(1.)=-inf,便于计算，改为-99999.0\n",
    "            #logodds[f]=deepcopy(default_logodds)\n",
    "            #pa=1.0/float(len(categories))\n",
    "            #logodds[f][range(len(categories))]=np.log(pa)-np.log(1.0-pa)\n",
    "            #logodds[f]=pd.Series(logodds[f])\n",
    "            #logodds[f].index=range(len(categories))\n",
    "            #N_count=N_count+1\n",
    "    #print(fieldStr+' N_count: '+str(N_count))\n",
    "    ########此部分代码，从逻辑上不应该出现在此处，但是为了编程的方便，放在了此处#########\n",
    "    #引进代码原作者的新思想\n",
    "    if testDF.shape[0]>0: #如果testDF里有样本,......\n",
    "        print('There are some new:'+fieldStr)\n",
    "        new_fields=sorted(testDF[fieldStr].unique())\n",
    "        new_F_counts=testDF.groupby(fieldStr).size()\n",
    "        only_new=set(new_fields+fields)-set(fields)\n",
    "        only_old=set(new_fields+fields)-set(new_fields)\n",
    "        in_both=set(new_fields).intersection(fields)\n",
    "        print('# only_new_fieldds:'+str(len(only_new)))\n",
    "        for f in only_new:\n",
    "            PA=new_F_counts[f]/float(len(testDF)+len(trainDF))\n",
    "            logoddsPF[f]=np.log(PA)-np.log(1.-PA)\n",
    "            logodds[f]=deepcopy(default_logodds)\n",
    "            logodds[f].index=range(len(categories))\n",
    "        for f in in_both:\n",
    "            PA=(F_counts[f]+new_F_counts[f])/float(len(testDF)+len(trainDF))\n",
    "            logoddsPF[f]=np.log(PA)-np.log(1.-PA)    \n",
    "    return logodds,logoddsPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(df,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y=False):\n",
    "    feature_list=df.columns.tolist()\n",
    "    if \"Descript\" in feature_list:\n",
    "        feature_list.remove(\"Descript\")\n",
    "    if \"Resolution\" in feature_list:\n",
    "        feature_list.remove(\"Resolution\")\n",
    "    if \"Category\" in feature_list:\n",
    "        feature_list.remove(\"Category\")\n",
    "    if \"Id\" in feature_list:\n",
    "        feature_list.remove(\"Id\")\n",
    "\n",
    "    cleanData=df[feature_list]\n",
    "    cleanData.index=range(len(df))\n",
    "    print(\"Creating address features\")###Creating address features###\n",
    "    address_features=cleanData[\"Address\"].apply(lambda x: logodds_A[x])\n",
    "    address_features.columns=[\"logodds_A\"+str(x) for x in range(len(address_features.columns))]\n",
    "    if needT_D_M_Y:\n",
    "        print(\"Creating time T_D_M_Y features\")###Creating time T_D_M_Y features###\n",
    "        T_D_M_Y_features=cleanData[\"T_D_M_Y\"].apply(lambda xx: logodds_T[xx])\n",
    "        T_D_M_Y_features.columns=[\"logodds_T\"+str(xx) for xx in range(len(T_D_M_Y_features.columns))]\n",
    "\n",
    "    print(\"Parsing dates\")            ###Creating address features###\n",
    "    cleanData[\"Time\"], cleanData[\"Day\"], cleanData[\"Month\"], cleanData[\"Year\"]=zip(*cleanData[\"Dates\"].apply(parse_time))\n",
    "    #     dummy_ranks_DAY = pd.get_dummies(cleanData['DayOfWeek'], prefix='DAY')\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    #     cleanData[\"DayOfWeek\"]=cleanData[\"DayOfWeek\"].apply(lambda x: days.index(x)/float(len(days)))\n",
    "    print(\"Creating one-hot variables\")\n",
    "    dummy_ranks_PD = pd.get_dummies(cleanData['PdDistrict'], prefix='PD')\n",
    "    dummy_ranks_DAY = pd.get_dummies(cleanData[\"DayOfWeek\"], prefix='DAY')\n",
    "    cleanData[\"IsInterection\"]=cleanData[\"Address\"].apply(lambda x: 1 if \"/\" in x else 0)\n",
    "    cleanData[\"logoddsPF_A\"]=cleanData[\"Address\"].apply(lambda x: logoddsPF_A[x])\n",
    "    if needT_D_M_Y:\n",
    "        cleanData[\"logoddsPF_T\"]=cleanData[\"T_D_M_Y\"].apply(lambda x: logoddsPF_T[x])\n",
    "    print(\"droping processed columns\")\n",
    "    cleanData=cleanData.drop(\"PdDistrict\",axis=1)\n",
    "    cleanData=cleanData.drop(\"DayOfWeek\",axis=1)\n",
    "    cleanData=cleanData.drop(\"Address\",axis=1)    \n",
    "    cleanData=cleanData.drop(\"Dates\",axis=1)\n",
    "    if needT_D_M_Y:\n",
    "        cleanData=cleanData.drop(\"T_D_M_Y\",axis=1)\n",
    "    feature_list=cleanData.columns.tolist()\n",
    "    print(\"joining one-hot features\")\n",
    "    if needT_D_M_Y:\n",
    "        features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:]).join(T_D_M_Y_features.iloc[:,:])\n",
    "    else:\n",
    "        features = cleanData[feature_list].join(dummy_ranks_PD.iloc[:,:]).join(dummy_ranks_DAY.iloc[:,:]).join(address_features.iloc[:,:])\n",
    "    print(\"creating new features\")\n",
    "    features[\"IsDup\"]=pd.Series(features.duplicated()|features.duplicated(keep='last')).apply(int)\n",
    "    features[\"Awake\"]=features[\"Time\"].apply(lambda x: 1 if (x==0 or (x>=8 and x<=23)) else 0)\n",
    "    features[\"Summer\"], features[\"Fall\"], features[\"Winter\"], features[\"Spring\"]=zip(*features[\"Month\"].apply(get_season))\n",
    "    if \"Category\" in df.columns:\n",
    "        labels = df[\"Category\"].astype('category')\n",
    "    else:\n",
    "        labels=None\n",
    "    return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, Y, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(X) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)#数值在[low, high)区间。\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, X.shape[-1]))\n",
    "        targets = np.zeros((len(rows),Y.shape[1]))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = X[indices]\n",
    "            targets[j] = Y[rows[j]+delay]\n",
    "            #print('In the Generator,   shape of samples is : ' +str(samples.shape)) \n",
    "            #print('In the Generator Funciotn, samples j is : '+str(indices))\n",
    "            #print('In the Generator Funciotn, targets j is : '+str(rows[j]+delay))\n",
    "#         print('# row of Val: '+str(targets.shape[0]))###Tian\n",
    "        \n",
    "        yield samples, targets\n",
    "    #Now here is the data generator that we will use. It yields a tuple (samples, targets) where samples is one batch of input data and targets is the corresponding array of target temperatures. It takes the following arguments:\n",
    "        # •data: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "        # •lookback: How many timesteps back should our input data go.\n",
    "        # •delay: How many timesteps in the future should our target be.\n",
    "        # •min_index and max_index: Indices in the data array that delimit which timesteps to draw from. This is useful for keeping a segment of the data for validation and another one for testing.\n",
    "        # •shuffle: Whether to shuffle our samples or draw them in chronological order.\n",
    "        # •batch_size: The number of samples per batch.\n",
    "        # •step: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_Val(X, Y, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6):\n",
    "    if max_index is None:\n",
    "        max_index = len(X) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)#数值在[low, high)区间。\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows), lookback // step, X.shape[-1]))\n",
    "        targets = np.zeros((len(rows),Y.shape[1]))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = X[indices]\n",
    "            targets[j] = Y[rows[j]+delay]\n",
    "            #print('In the Generator Val,   shape of samples is : '+str(samples.shape)) \n",
    "            #print('In the Generator Val Funciotn, samples j is : '+str(indices))\n",
    "            #print('In the Generator Val Funciotn, targets j is : '+str(rows[j]+delay))\n",
    "#         print('# row of Val: '+str(targets.shape[0]))###Tian\n",
    "        \n",
    "        yield samples, targets\n",
    "    #Now here is the data generator that we will use. It yields a tuple (samples, targets) where samples is one batch of input data and targets is the corresponding array of target temperatures. It takes the following arguments:\n",
    "        # •data: The original array of floating point data, which we just normalized in the code snippet above.\n",
    "        # •lookback: How many timesteps back should our input data go.\n",
    "        # •delay: How many timesteps in the future should our target be.\n",
    "        # •min_index and max_index: Indices in the data array that delimit which timesteps to draw from. This is useful for keeping a segment of the data for validation and another one for testing.\n",
    "        # •shuffle: Whether to shuffle our samples or draw them in chronological order.\n",
    "        # •batch_size: The number of samples per batch.\n",
    "        # •step: The period, in timesteps, at which we sample data. We will set it 6 in order to draw one data point every hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of OrginalAllDF: (145962, 9)\n",
      "The shape of AllDF after del wrong X and Y values: (145960, 9)\n",
      "The shape of AllDF after drop_duplicates: (145876, 9)\n",
      "(145859, 2)\n",
      "Address_counts_allDF_trainDF_testDF: 17161_17161_0\n",
      "The # of AllDF, AllTrain, AllTest, is: 145876,145876,0\n",
      "-----------LOGOODS: Address-------------\n",
      "-----------LOGOODS: T_D_M_Y-------------\n",
      "-----------LOGOODS: parse_data of Alltrain  -------------\n",
      "Creating address features\n",
      "Creating time T_D_M_Y features\n",
      "Parsing dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating one-hot variables\n",
      "droping processed columns\n",
      "joining one-hot features\n",
      "creating new features\n",
      "['X', 'Y', 'Time', 'Day', 'Month', 'Year', 'IsInterection', 'logoddsPF_A', 'logoddsPF_T', 'PD_星期一', 'PD_星期三', 'PD_星期二', 'PD_星期五', 'PD_星期六', 'PD_星期四', 'PD_星期日', 'DAY_星期一', 'DAY_星期三', 'DAY_星期二', 'DAY_星期五', 'DAY_星期六', 'DAY_星期四', 'DAY_星期日', 'logodds_A0', 'logodds_A1', 'logodds_A2', 'logodds_A3', 'logodds_A4', 'logodds_A5', 'logodds_A6', 'logodds_A7', 'logodds_A8', 'logodds_A9', 'logodds_A10', 'logodds_A11', 'logodds_A12', 'logodds_A13', 'logodds_A14', 'logodds_A15', 'logodds_A16', 'logodds_A17', 'logodds_A18', 'logodds_A19', 'logodds_A20', 'logodds_A21', 'logodds_A22', 'logodds_A23', 'logodds_A24', 'logodds_A25', 'logodds_A26', 'logodds_A27', 'logodds_A28', 'logodds_A29', 'logodds_A30', 'logodds_A31', 'logodds_A32', 'logodds_A33', 'logodds_A34', 'logodds_A35', 'logodds_A36', 'logodds_A37', 'logodds_A38', 'logodds_A39', 'logodds_A40', 'logodds_A41', 'logodds_A42', 'logodds_A43', 'logodds_A44', 'logodds_A45', 'logodds_A46', 'logodds_A47', 'logodds_A48', 'logodds_A49', 'logodds_T0', 'logodds_T1', 'logodds_T2', 'logodds_T3', 'logodds_T4', 'logodds_T5', 'logodds_T6', 'logodds_T7', 'logodds_T8', 'logodds_T9', 'logodds_T10', 'logodds_T11', 'logodds_T12', 'logodds_T13', 'logodds_T14', 'logodds_T15', 'logodds_T16', 'logodds_T17', 'logodds_T18', 'logodds_T19', 'logodds_T20', 'logodds_T21', 'logodds_T22', 'logodds_T23', 'logodds_T24', 'logodds_T25', 'logodds_T26', 'logodds_T27', 'logodds_T28', 'logodds_T29', 'logodds_T30', 'logodds_T31', 'logodds_T32', 'logodds_T33', 'logodds_T34', 'logodds_T35', 'logodds_T36', 'logodds_T37', 'logodds_T38', 'logodds_T39', 'logodds_T40', 'logodds_T41', 'logodds_T42', 'logodds_T43', 'logodds_T44', 'logodds_T45', 'logodds_T46', 'logodds_T47', 'logodds_T48', 'logodds_T49', 'IsDup', 'Awake', 'Summer', 'Fall', 'Winter', 'Spring']\n",
      "129\n",
      "------------Attention: we do not RandomOverSampler---------------\n",
      "------------ConsiderTime:  Sorting--------------\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "ConsiderTime=True#False# True##trainDF和testDF分割时是否考虑时间问题，即是否需要随机打乱。True:按照‘Dates’列进行降序排列,False：随机打乱样本的顺序，\n",
    "Rate_ALL=0.0 #0.0即不保留测试机\n",
    "needOverSampler=False\n",
    "needT_D_M_Y=True #False  使用_T_D_M_Y和周几\n",
    "allDF=pd.read_csv(\"./HuZhou.csv\")\n",
    "print('The shape of OrginalAllDF: '+str(allDF.shape))\n",
    "\n",
    "xy_scaler=preprocessing.StandardScaler()\n",
    "xy_scaler.fit(allDF[[\"X\",\"Y\"]])\n",
    "allDF[[\"X\",\"Y\"]]=xy_scaler.transform(allDF[[\"X\",\"Y\"]])\n",
    "allDF=allDF[abs(allDF[\"Y\"])<100]\n",
    "allDF.index=range(len(allDF))\n",
    "print('The shape of AllDF after del wrong X and Y values: '+str(allDF.shape))\n",
    "\n",
    "def listCat(x):\n",
    "    return list(x)\n",
    "allDF.drop_duplicates(inplace=True,subset=['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Category'])\n",
    "Train_duplicated=pd.pivot_table(allDF,index=['Dates','DayOfWeek','PdDistrict', 'Address', 'X', 'Y'], values='Category',aggfunc=[len,listCat])\n",
    "print('The shape of AllDF after drop_duplicates: '+str(allDF.shape))\n",
    "print(Train_duplicated.shape)\n",
    "\n",
    "trainDF,testDF=train_test_split_DataFrame(allDF, test_size=Rate_ALL, considerTime=ConsiderTime, random_state=None)\n",
    "print('Address_counts_allDF_trainDF_testDF: ' + str(len(allDF[\"Address\"].unique())) + '_'+ str(len(trainDF[\"Address\"].unique())) + '_' + str(len(testDF[\"Address\"].unique())))\n",
    "\n",
    "N_AllSample=allDF.shape[0]\n",
    "N_AllTrain=trainDF.shape[0]\n",
    "N_AllTest=testDF.shape[0]\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "print('The # of AllDF, AllTrain, AllTest, is: '+str(N_AllSample)+','+str(N_AllTrain)+','+str(N_AllTest))\n",
    "#################Now proceed as before#################\n",
    "print('-----------LOGOODS: Address-------------')\n",
    "logodds_A,logoddsPF_A=field2Vec(trainDF,testDF,\"Address\")\n",
    "if needT_D_M_Y:\n",
    "    trainDF[\"T_D_M_Y\"]=trainDF[\"Dates\"].apply(Dates2TDMY)\n",
    "    trainDF[\"T_D_M_Y\"]=trainDF[\"T_D_M_Y\"]+trainDF[\"DayOfWeek\"]\n",
    "    if Rate_ALL>0:\n",
    "        testDF[[\"X\",\"Y\"]]=xy_scaler.transform(testDF[[\"X\",\"Y\"]])\n",
    "        testDF[\"T_D_M_Y\"]=testDF[\"Dates\"].apply(Dates2TDMY)\n",
    "        testDF[\"T_D_M_Y\"]=testDF[\"T_D_M_Y\"]+testDF[\"DayOfWeek\"]\n",
    "    print('-----------LOGOODS: T_D_M_Y-------------')\n",
    "    logodds_T,logoddsPF_T=field2Vec(trainDF,testDF,\"T_D_M_Y\")    \n",
    "else:\n",
    "    logodds_T=None\n",
    "    logoddsPF_T=None\n",
    "    \n",
    "print('-----------LOGOODS: parse_data of Alltrain  -------------')\n",
    "features, labels=parse_data(trainDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y) \n",
    "if Rate_ALL>0:\n",
    "    print('-----------LOGOODS: parse_data of Alltest  -------------')\n",
    "    features_test, labels_test=parse_data(testDF,logodds_A,logoddsPF_A,logodds_T,logoddsPF_T,needT_D_M_Y)###########和训练集使用同样的时间和地点Logoodds值#####\n",
    "    x_test=features_test.values\n",
    "    y_test=labels_test.values\n",
    "    y_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(y_test)), num_classes=N_CLASS)\n",
    "\n",
    "print(features.columns.tolist())\n",
    "print(len(features.columns))\n",
    "\n",
    "collist=features.columns.tolist()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(features)\n",
    "features[collist]=scaler.transform(features)\n",
    "if Rate_ALL>0:\n",
    "    features_test[collist]=scaler.transform(features_test)###########和训练集使用同样的scaler值#####\n",
    "######################################################\n",
    "#############################先进行过采样，然后再根据时间来排序##################################\n",
    "if needOverSampler:\n",
    "    print('------------RandomOverSampler--------------')\n",
    "    ros = RandomOverSampler()\n",
    "    featuresArrayOverSampler, labelsArrayOverSampler = ros.fit_resample(features.values,labels.values)#####过采样#####\n",
    "    N_AllTrain_OverSampler=int(featuresArrayOverSampler.shape[0])\n",
    "    print('Shape of OverSampler of AllTrain: '+str(featuresArrayOverSampler.shape))\n",
    "else:\n",
    "    featuresArrayOverSampler=features.values\n",
    "    labelsArrayOverSampler=labels.values\n",
    "    N_AllTrain_OverSampler=int(featuresArrayOverSampler.shape[0])\n",
    "    print('------------Attention: we do not RandomOverSampler---------------')\n",
    "if ConsiderTime:\n",
    "    #####按照年（第6列）月（第5列）日（第4列）时（第3列）排序\n",
    "    print('------------ConsiderTime:  Sorting--------------')\n",
    "    time_temp=featuresArrayOverSampler[:,2]+np.dot(featuresArrayOverSampler[:,3],100)+np.dot(featuresArrayOverSampler[:,4],10000)+np.dot(featuresArrayOverSampler[:,5],1000000)\n",
    "    features_label_time=np.column_stack((featuresArrayOverSampler,labelsArrayOverSampler))\n",
    "    features_label_time=np.column_stack((features_label_time,time_temp))\n",
    "    features_label_time =features_label_time[np.argsort(features_label_time[:,-1])]\n",
    "    labelsArrayOverSampler=features_label_time[:,-2]\n",
    "    featuresArrayOverSampler=features_label_time[:,0:featuresArrayOverSampler.shape[1]]\n",
    "    del features_label_time\n",
    "    #############################先进行过采样，然后再根据时间来排序----结束############################\n",
    "if Rate_ALL>0:\n",
    "    print('------------RandomOverSampler for AllTest--------------')\n",
    "    ros = RandomOverSampler()\n",
    "    featuresArray_test, labelsArray_test = ros.fit_resample(features_test.values,labels_test.values)#####过采样#####\n",
    "    N_AllTest_OverSampler=int(featuresArray_test.shape[0])\n",
    "    labelsArray_test = keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArray_test)), num_classes=N_CLASS)\n",
    "    print('Shape of OverSampler of AllTest: '+str(featuresArray_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_Train_OverSampler= 29175\n",
      "BlockSize is: 116\n",
      "-----------------Building DNN model---------------------\n",
      "------------Building LSTM model--------------\n"
     ]
    }
   ],
   "source": [
    "DnnTrainFromZero=False\n",
    "RnnTrainFromZero=False\n",
    "ShuffleInTraining=False\n",
    "N_EPOCHS_0_DNN=7\n",
    "N_EPOCHS_DNN=3\n",
    "N_EPOCHS_0_RNN=17\n",
    "N_EPOCHS_RNN=1\n",
    "N_HN_1=128\n",
    "N_HN=64\n",
    "N_LAYERS=1\n",
    "N_BATCH=128\n",
    "Rate_Val=0.8#用20%作为原始训练集，分别训练DNN和RNN\n",
    "N_Split=1000#400#500\n",
    "delay=-1\n",
    "N_Val_OverSampler=int(np.around(N_AllTrain_OverSampler*Rate_Val))\n",
    "N_Train_OverSampler=int(N_AllTrain_OverSampler-N_Val_OverSampler)\n",
    "print('N_Train_OverSampler= '+str(N_Train_OverSampler))\n",
    "N_CLASS=len(allDF[\"Category\"].unique())\n",
    "input_dim=featuresArrayOverSampler.shape[1]\n",
    "output_dim=N_CLASS\n",
    "BlockSize=int(np.floor(N_Val_OverSampler/N_Split))\n",
    "print('BlockSize is: '+str(BlockSize)) \n",
    "lookback=int(BlockSize)\n",
    "\n",
    "print('-----------------Building DNN model---------------------')\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HN_1,input_dim=input_dim))\n",
    "model.add(BatchNormalization())\n",
    "model.add(PReLU())\n",
    "for i in range(N_LAYERS):\n",
    "    model.add(Dense(N_HN))\n",
    "    model.add(BatchNormalization())   \n",
    "    model.add(PReLU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(output_dim))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "\n",
    "print('------------Building LSTM model--------------')\n",
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(LSTM(N_HN_1,dropout=0.5, recurrent_dropout=0.5,return_sequences=True,input_shape=(None,input_dim)))\n",
    "RNNmodel.add(LSTM(N_HN,dropout=0.5, recurrent_dropout=0.5,return_sequences=True,))\n",
    "RNNmodel.add(LSTM(N_HN,dropout=0.5, recurrent_dropout=0.5))\n",
    "RNNmodel.add(BatchNormalization())\n",
    "RNNmodel.add(Dense(output_dim))\n",
    "RNNmodel.add(Activation('softmax'))\n",
    "# RNNmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "RNNmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01),metrics=['accuracy', metrics.top_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Prepare dataset for DNN---------------------------------\n",
      "--------Spllit train val according to time!---------\n",
      "(29175, 129)\n",
      "The shape of x_val_i is: (1, 129)\n",
      "N_Train_OverSampler is: 29175\n",
      "--------------------------Generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------Prepare dataset for DNN---------------------------------')\n",
    "labelsArrayOverSampler_1hot=keras.utils.to_categorical(LabelEncoder().fit_transform(np.array(labelsArrayOverSampler)), num_classes=N_CLASS)\n",
    "if ConsiderTime:\n",
    "    print('--------Spllit train val according to time!---------')\n",
    "    x_train=featuresArrayOverSampler[0:N_Train_OverSampler,:]\n",
    "    y_train=labelsArrayOverSampler_1hot[0:N_Train_OverSampler,:]\n",
    "else:\n",
    "    x_train,x_val,y_train,y_val = train_test_split(featuresArrayOverSampler,labelsArrayOverSampler_1hot,test_size=N_Val_OverSampler,train_size=N_Train_OverSampler, shuffle=True)\n",
    "print(str(x_train.shape))\n",
    "x_val_i=featuresArrayOverSampler[N_Train_OverSampler:N_Train_OverSampler+1,:]\n",
    "y_val_i=labelsArrayOverSampler_1hot[N_Train_OverSampler:N_Train_OverSampler+1,:]\n",
    "print('The shape of x_val_i is: '+str(x_val_i.shape))\n",
    "print('N_Train_OverSampler is: '+str(N_Train_OverSampler))\n",
    "\n",
    "print('--------------------------Generator AllTrain_set, Train_set and Val_set for LSTM---------------------------------')\n",
    "train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=0, max_index=N_Train_OverSampler+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "val_generator=generator_Val(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=N_Train_OverSampler-lookback+1, max_index=N_Train_OverSampler+2, shuffle=False, batch_size=1, step=1)\n",
    "#数值在[min_index, max_index)区间。当delay=1时，就是用[min_index, max_index)区间的样本预测，第max_index个样本。当delay=2时，就是预测第max_index+1个\n",
    "train_steps= (N_Train_OverSampler-lookback) // N_BATCH\n",
    "val_steps =  1 #(N_Val-lookback) // N_BATCH\n",
    "# val_xx,val_yy=next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "------------Dnn Model has been loaded!!!-----------------\n"
     ]
    }
   ],
   "source": [
    "if DnnTrainFromZero:\n",
    "    print('------------DNN Training Go! Go! Go!!!!-----------')\n",
    "    fitting=model.fit(x_train, y_train, epochs=N_EPOCHS_0_DNN, batch_size=N_BATCH,verbose=1,validation_data=(x_val_i,y_val_i),shuffle=True)\n",
    "    #score01=model.predict(x_val_i, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    #score0=model.evaluate(x=x_val_i, y=y_val_i, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    model.save('jjs_model_Dnn0307V1.h5')\n",
    "    print('------------DNN train finished--------------------')\n",
    "else:\n",
    "    model=load_model('jjs_model_Dnn0307V1.h5')\n",
    "    print('------------Dnn Model has been loaded!!!-----------------')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------LSTM Model has been loaded!!!-----------------\n"
     ]
    }
   ],
   "source": [
    "if RnnTrainFromZero:\n",
    "    print('---------------------------------------LSTM GO GO GO!!!!---------------------------------------------')\n",
    "    #train_xx,train_yy=next(train_generator)\n",
    "    #print('Y For RNN Train: '+str(train_yy))    \n",
    "    #val_xx,val_yy=next(val_generator)\n",
    "    #print('Y For RNN Val: '+str(val_yy))\n",
    "    history = RNNmodel.fit_generator(train_generator,steps_per_epoch=train_steps,epochs=N_EPOCHS_0_RNN,verbose=1,validation_data=val_generator,validation_steps=val_steps)\n",
    "    print('------------LSTM train finished--------------------')\n",
    "    RNNmodel.save('jjs_model_0307LSTMV1.h5')\n",
    "else:\n",
    "    RNNmodel=load_model('jjs_model_0307LSTMV1.h5')\n",
    "    print('------------LSTM Model has been loaded!!!-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockSize_train is: 116\n",
      "-----------------Start the loop training!!---------------------\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "[0.6316 0.5588 0.6148 0.    ]\n"
     ]
    }
   ],
   "source": [
    "####prepare the data for R&D_Model\n",
    "RNNmodel=load_model('jjs_model_0307LSTMV1.h5')\n",
    "model=load_model('jjs_model_Dnn0307V1.h5')\n",
    "\n",
    "N_Split_train=250 #1000\n",
    "N_delt=10#100\n",
    "BlockSize_train=int(np.floor(1*N_Train_OverSampler/N_Split_train))\n",
    "print('BlockSize_train is: '+str(BlockSize_train)) \n",
    "lookback_train=int(BlockSize_train)\n",
    "\n",
    "print('-----------------Start the loop training!!---------------------')\n",
    "ACC=np.zeros([N_Split_train*N_delt,4])\n",
    "P_DNN=np.zeros([N_Split_train*N_delt, labelsArrayOverSampler_1hot.shape[-1]])\n",
    "P_RNN=np.zeros([N_Split_train*N_delt, labelsArrayOverSampler_1hot.shape[-1]])\n",
    "G_NN =np.zeros([N_Split_train*N_delt, labelsArrayOverSampler_1hot.shape[-1]])\n",
    "for delt_i in range(N_delt):\n",
    "    print(delt_i)\n",
    "    for i_s in range(N_Split_train):    #N_Split\n",
    "        delt=delt_i*(BlockSize_train//N_delt)\n",
    "        StartIndexTrain=delt+i_s*BlockSize_train\n",
    "        StopIndexTrain =delt+(i_s+1)*BlockSize_train\n",
    "        \n",
    "        x_train=featuresArrayOverSampler[StartIndexTrain:StopIndexTrain,:]\n",
    "        y_train=labelsArrayOverSampler_1hot[StartIndexTrain:StopIndexTrain,:]\n",
    "\n",
    "        StartIndexVal=delt+(i_s+1)*BlockSize_train\n",
    "        StopIndexVal =delt+(i_s+1)*BlockSize_train+1\n",
    "        \n",
    "        x_val_i=featuresArrayOverSampler[StartIndexVal:StopIndexVal,:]\n",
    "        y_val_i=labelsArrayOverSampler_1hot[StartIndexVal:StopIndexVal,:]\n",
    "    #     print('The shape of x_val_i is: '+str(x_val_i.shape))\n",
    "    #     print(StopIndexVal)\n",
    "    #     fittingDNN=model.fit(x_train, y_train, epochs=N_EPOCHS_DNN, batch_size=N_BATCH,verbose=0,validation_data=(x_val_i,y_val_i),shuffle=True)\n",
    "        scoreDNN=model.predict(x_val_i, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "\n",
    "        train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback_train, delay=delay, min_index=StartIndexTrain, max_index=StopIndexTrain+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    #     fittingRNN=RNNmodel.fit_generator(train_generator,steps_per_epoch=(2.5*lookback)//N_BATCH,epochs=N_EPOCHS_RNN,verbose=0)\n",
    "        #train_xx,train_yy=next(train_generator)\n",
    "        #print('Y For RNN Train: '+str(train_yy))\n",
    "\n",
    "        val_generator=generator_Val(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback_train, delay=delay, min_index=StopIndexVal-lookback, max_index=StopIndexVal+2,shuffle=False, batch_size=1, step=1)\n",
    "    #     val_xx,val_yy=next(val_generator)\n",
    "    #     print('Y For RNN Val: '+str(val_yy))\n",
    "    #     print(StartIndexVal)\n",
    "        scoreRNN=RNNmodel.predict(val_generator, batch_size=None, verbose=0, steps=1, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "        #print('Y For DNN Val: '+str(y_val_i))\n",
    "        P_DNN[delt_i*N_Split_train+i_s,:]=scoreDNN\n",
    "        P_RNN[delt_i*N_Split_train+i_s,:]=scoreRNN \n",
    "        G_NN[delt_i*N_Split_train+i_s,:] =y_val_i\n",
    "\n",
    "        pre_Dnn=compareResult(scoreDNN,y_val_i)\n",
    "        pre_Rnn=compareResult(scoreRNN,y_val_i)\n",
    "        pre_Plus,pre_Mult=comparePlusMultResult(scoreDNN,scoreRNN,y_val_i)        \n",
    "    #     print('i_s:'+str(i_s)+'------DNN & RNN & pre_Plus & pre_Mult = '+str(pre_Dnn)+'---'+str(pre_Rnn)+'---'+str(pre_Plus)+'---'+str(pre_Mult))\n",
    "        ACC[delt_i*N_Split_train+i_s,0]=pre_Dnn\n",
    "        ACC[delt_i*N_Split_train+i_s,1]=pre_Rnn\n",
    "        ACC[delt_i*N_Split_train+i_s,2]=pre_Plus\n",
    "        ACC[delt_i*N_Split_train+i_s,3]=pre_Mult    \n",
    "print(np.mean(ACC,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Start the loop training!!---------------------\n",
      "[0.585 0.292 0.511 0.   ]\n"
     ]
    }
   ],
   "source": [
    "RNNmodel=load_model('jjs_model_0307LSTMV1.h5')\n",
    "model=load_model('jjs_model_Dnn0307V1.h5')\n",
    "print('-----------------Start the loop training!!---------------------')\n",
    "ACC_test=np.zeros([N_Split,4])\n",
    "P_DNN_test=np.zeros([N_Split,labelsArrayOverSampler_1hot.shape[-1]])\n",
    "P_RNN_test=np.zeros([N_Split,labelsArrayOverSampler_1hot.shape[-1]])\n",
    "G_NN_test =np.zeros([N_Split,labelsArrayOverSampler_1hot.shape[-1]])\n",
    "for i_s in range(N_Split):    #N_Split\n",
    "    StartIndexTrain=N_Train_OverSampler+i_s*BlockSize\n",
    "    StopIndexTrain =N_Train_OverSampler+(i_s+1)*BlockSize\n",
    "    x_train=featuresArrayOverSampler[StartIndexTrain:StopIndexTrain,:]\n",
    "    y_train=labelsArrayOverSampler_1hot[StartIndexTrain:StopIndexTrain,:]\n",
    "    #print('The shape of x_train is: '+str(x_train.shape))\n",
    "    StartIndexVal=N_Train_OverSampler+(i_s+1)*BlockSize\n",
    "    StopIndexVal =N_Train_OverSampler+(i_s+1)*BlockSize+1\n",
    "    x_val_i=featuresArrayOverSampler[StartIndexVal:StopIndexVal,:]\n",
    "    y_val_i=labelsArrayOverSampler_1hot[StartIndexVal:StopIndexVal,:]\n",
    "    #print('The shape of x_val_i is: '+str(x_val_i.shape))\n",
    "    #print(StopIndexVal)\n",
    "    fittingDNN=model.fit(x_train, y_train, epochs=N_EPOCHS_DNN, batch_size=N_BATCH,verbose=0,validation_data=(x_val_i,y_val_i),shuffle=True)\n",
    "    scoreDNN=model.predict(x_val_i, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "        \n",
    "    train_generator=generator(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=StartIndexTrain, max_index=StopIndexTrain+1, shuffle=ShuffleInTraining, batch_size=N_BATCH, step=1)\n",
    "    fittingRNN=RNNmodel.fit_generator(train_generator,steps_per_epoch=(2.5*lookback)//N_BATCH,epochs=N_EPOCHS_RNN,verbose=0)\n",
    "    #train_xx,train_yy=next(train_generator)\n",
    "    #print('Y For RNN Train: '+str(train_yy))\n",
    "    \n",
    "    val_generator=generator_Val(featuresArrayOverSampler, labelsArrayOverSampler_1hot, lookback=lookback, delay=delay, min_index=StopIndexVal-lookback, max_index=StopIndexVal+2,shuffle=False, batch_size=1, step=1)\n",
    "#     val_xx,val_yy=next(val_generator)\n",
    "#     print('Y For RNN Val: '+str(val_yy))\n",
    "#     print(StartIndexVal)\n",
    "    scoreRNN=RNNmodel.predict(val_generator, batch_size=None, verbose=0, steps=1, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
    "    #print('Y For DNN Val: '+str(y_val_i))\n",
    "    P_DNN_test[i_s,:]=scoreDNN\n",
    "    P_RNN_test[i_s,:]=scoreRNN \n",
    "    G_NN_test[i_s,:] =y_val_i\n",
    "    \n",
    "    pre_Dnn=compareResult(scoreDNN,y_val_i)\n",
    "    pre_Rnn=compareResult(scoreRNN,y_val_i)\n",
    "    pre_Plus,pre_Mult=comparePlusMultResult(scoreDNN,scoreRNN,y_val_i)        \n",
    "#     print('i_s:'+str(i_s)+'------DNN & RNN & pre_Plus & pre_Mult = '+str(pre_Dnn)+'---'+str(pre_Rnn)+'---'+str(pre_Plus)+'---'+str(pre_Mult))\n",
    "    ACC_test[i_s,0]=pre_Dnn\n",
    "    ACC_test[i_s,1]=pre_Rnn\n",
    "    ACC_test[i_s,2]=pre_Plus\n",
    "    ACC_test[i_s,3]=pre_Mult    \n",
    "print(np.mean(ACC_test,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "1000\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 20,018\n",
      "Trainable params: 19,762\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/117\n",
      " - 2s - loss: 3.0441 - accuracy: 0.3532 - top_k_categorical_accuracy: 0.5831 - val_loss: 2.3121 - val_accuracy: 0.5510 - val_top_k_categorical_accuracy: 0.8840\n",
      "Epoch 2/117\n",
      " - 2s - loss: 2.0609 - accuracy: 0.5353 - top_k_categorical_accuracy: 0.8317 - val_loss: 1.8178 - val_accuracy: 0.5500 - val_top_k_categorical_accuracy: 0.8870\n",
      "Epoch 3/117\n",
      " - 2s - loss: 1.8662 - accuracy: 0.5668 - top_k_categorical_accuracy: 0.8601 - val_loss: 2.7265 - val_accuracy: 0.5510 - val_top_k_categorical_accuracy: 0.8880\n",
      "Epoch 4/117\n",
      " - 2s - loss: 1.7546 - accuracy: 0.5797 - top_k_categorical_accuracy: 0.8779 - val_loss: 3.0226 - val_accuracy: 0.5510 - val_top_k_categorical_accuracy: 0.8870\n",
      "Epoch 5/117\n",
      " - 2s - loss: 1.7066 - accuracy: 0.5844 - top_k_categorical_accuracy: 0.8847 - val_loss: 3.0791 - val_accuracy: 0.5530 - val_top_k_categorical_accuracy: 0.8860\n",
      "Epoch 6/117\n",
      " - 1s - loss: 1.6882 - accuracy: 0.5859 - top_k_categorical_accuracy: 0.8824 - val_loss: 3.0186 - val_accuracy: 0.5530 - val_top_k_categorical_accuracy: 0.8900\n",
      "Epoch 7/117\n",
      " - 1s - loss: 1.6521 - accuracy: 0.5919 - top_k_categorical_accuracy: 0.8820 - val_loss: 2.9113 - val_accuracy: 0.5560 - val_top_k_categorical_accuracy: 0.8870\n",
      "Epoch 8/117\n",
      " - 2s - loss: 1.6162 - accuracy: 0.5943 - top_k_categorical_accuracy: 0.8840 - val_loss: 2.7571 - val_accuracy: 0.5600 - val_top_k_categorical_accuracy: 0.8920\n",
      "Epoch 9/117\n",
      " - 1s - loss: 1.6205 - accuracy: 0.5941 - top_k_categorical_accuracy: 0.8872 - val_loss: 2.6704 - val_accuracy: 0.5580 - val_top_k_categorical_accuracy: 0.8890\n",
      "Epoch 10/117\n",
      " - 1s - loss: 1.6004 - accuracy: 0.5931 - top_k_categorical_accuracy: 0.8884 - val_loss: 2.5250 - val_accuracy: 0.5640 - val_top_k_categorical_accuracy: 0.8930\n",
      "Epoch 11/117\n",
      " - 2s - loss: 1.5997 - accuracy: 0.5961 - top_k_categorical_accuracy: 0.8924 - val_loss: 2.5678 - val_accuracy: 0.5600 - val_top_k_categorical_accuracy: 0.8890\n",
      "Epoch 12/117\n",
      " - 2s - loss: 1.5871 - accuracy: 0.5956 - top_k_categorical_accuracy: 0.8901 - val_loss: 2.4445 - val_accuracy: 0.5670 - val_top_k_categorical_accuracy: 0.8860\n",
      "Epoch 13/117\n",
      " - 2s - loss: 1.5681 - accuracy: 0.5953 - top_k_categorical_accuracy: 0.8909 - val_loss: 2.3603 - val_accuracy: 0.5710 - val_top_k_categorical_accuracy: 0.8930\n",
      "Epoch 14/117\n",
      " - 1s - loss: 1.5563 - accuracy: 0.5979 - top_k_categorical_accuracy: 0.8923 - val_loss: 2.3085 - val_accuracy: 0.5700 - val_top_k_categorical_accuracy: 0.8890\n",
      "Epoch 15/117\n",
      " - 1s - loss: 1.5569 - accuracy: 0.5948 - top_k_categorical_accuracy: 0.8879 - val_loss: 2.2393 - val_accuracy: 0.5780 - val_top_k_categorical_accuracy: 0.8920\n",
      "Epoch 16/117\n",
      " - 2s - loss: 1.5395 - accuracy: 0.6021 - top_k_categorical_accuracy: 0.8925 - val_loss: 2.2330 - val_accuracy: 0.5720 - val_top_k_categorical_accuracy: 0.8920\n",
      "Epoch 17/117\n",
      " - 1s - loss: 1.5288 - accuracy: 0.6008 - top_k_categorical_accuracy: 0.8907 - val_loss: 2.2438 - val_accuracy: 0.5710 - val_top_k_categorical_accuracy: 0.8950\n",
      "Epoch 18/117\n",
      " - 1s - loss: 1.5420 - accuracy: 0.5956 - top_k_categorical_accuracy: 0.8924 - val_loss: 2.2042 - val_accuracy: 0.5680 - val_top_k_categorical_accuracy: 0.9000\n",
      "Epoch 19/117\n",
      " - 1s - loss: 1.5341 - accuracy: 0.5944 - top_k_categorical_accuracy: 0.8903 - val_loss: 2.1535 - val_accuracy: 0.5750 - val_top_k_categorical_accuracy: 0.8910\n",
      "Epoch 20/117\n",
      " - 1s - loss: 1.5327 - accuracy: 0.5988 - top_k_categorical_accuracy: 0.8941 - val_loss: 2.0808 - val_accuracy: 0.5810 - val_top_k_categorical_accuracy: 0.8910\n",
      "Epoch 21/117\n",
      " - 1s - loss: 1.5226 - accuracy: 0.5991 - top_k_categorical_accuracy: 0.8928 - val_loss: 2.0856 - val_accuracy: 0.5740 - val_top_k_categorical_accuracy: 0.8910\n",
      "Epoch 22/117\n",
      " - 1s - loss: 1.5150 - accuracy: 0.6007 - top_k_categorical_accuracy: 0.8920 - val_loss: 2.0558 - val_accuracy: 0.5740 - val_top_k_categorical_accuracy: 0.8910\n",
      "Epoch 23/117\n",
      " - 1s - loss: 1.5205 - accuracy: 0.6019 - top_k_categorical_accuracy: 0.8897 - val_loss: 2.0518 - val_accuracy: 0.5750 - val_top_k_categorical_accuracy: 0.8930\n",
      "Epoch 24/117\n",
      " - 1s - loss: 1.5048 - accuracy: 0.5996 - top_k_categorical_accuracy: 0.8928 - val_loss: 1.9998 - val_accuracy: 0.5760 - val_top_k_categorical_accuracy: 0.8980\n",
      "Epoch 25/117\n",
      " - 1s - loss: 1.4983 - accuracy: 0.6009 - top_k_categorical_accuracy: 0.8941 - val_loss: 1.9621 - val_accuracy: 0.5780 - val_top_k_categorical_accuracy: 0.8960\n",
      "Epoch 26/117\n",
      " - 2s - loss: 1.5023 - accuracy: 0.5992 - top_k_categorical_accuracy: 0.8932 - val_loss: 1.9195 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8980\n",
      "Epoch 27/117\n",
      " - 2s - loss: 1.4966 - accuracy: 0.5981 - top_k_categorical_accuracy: 0.8977 - val_loss: 1.8954 - val_accuracy: 0.5830 - val_top_k_categorical_accuracy: 0.8910\n",
      "Epoch 28/117\n",
      " - 2s - loss: 1.5004 - accuracy: 0.6004 - top_k_categorical_accuracy: 0.8963 - val_loss: 1.9380 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8920\n",
      "Epoch 29/117\n",
      " - 1s - loss: 1.4972 - accuracy: 0.6020 - top_k_categorical_accuracy: 0.8959 - val_loss: 1.8631 - val_accuracy: 0.5800 - val_top_k_categorical_accuracy: 0.8910\n",
      "Epoch 30/117\n",
      " - 1s - loss: 1.4983 - accuracy: 0.6012 - top_k_categorical_accuracy: 0.8976 - val_loss: 1.8543 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8890\n",
      "Epoch 31/117\n",
      " - 1s - loss: 1.4819 - accuracy: 0.5973 - top_k_categorical_accuracy: 0.8977 - val_loss: 1.8712 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8870\n",
      "Epoch 32/117\n",
      " - 1s - loss: 1.4868 - accuracy: 0.6057 - top_k_categorical_accuracy: 0.8956 - val_loss: 1.9003 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8950\n",
      "Epoch 33/117\n",
      " - 1s - loss: 1.4911 - accuracy: 0.6040 - top_k_categorical_accuracy: 0.8928 - val_loss: 1.8647 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8880\n",
      "Epoch 34/117\n",
      " - 2s - loss: 1.4835 - accuracy: 0.5996 - top_k_categorical_accuracy: 0.8943 - val_loss: 1.8669 - val_accuracy: 0.5820 - val_top_k_categorical_accuracy: 0.8930\n",
      "Epoch 35/117\n",
      " - 2s - loss: 1.4845 - accuracy: 0.6039 - top_k_categorical_accuracy: 0.8955 - val_loss: 1.8713 - val_accuracy: 0.5800 - val_top_k_categorical_accuracy: 0.8920\n",
      "Epoch 36/117\n",
      " - 2s - loss: 1.4734 - accuracy: 0.6023 - top_k_categorical_accuracy: 0.8979 - val_loss: 1.8359 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8970\n",
      "Epoch 37/117\n",
      " - 2s - loss: 1.4734 - accuracy: 0.6021 - top_k_categorical_accuracy: 0.8985 - val_loss: 1.8277 - val_accuracy: 0.5870 - val_top_k_categorical_accuracy: 0.8920\n",
      "Epoch 38/117\n",
      " - 2s - loss: 1.4817 - accuracy: 0.6032 - top_k_categorical_accuracy: 0.8955 - val_loss: 1.8097 - val_accuracy: 0.5860 - val_top_k_categorical_accuracy: 0.8950\n",
      "Epoch 39/117\n",
      " - 2s - loss: 1.4691 - accuracy: 0.6041 - top_k_categorical_accuracy: 0.8960 - val_loss: 1.8059 - val_accuracy: 0.5930 - val_top_k_categorical_accuracy: 0.8930\n",
      "Epoch 40/117\n",
      " - 1s - loss: 1.4674 - accuracy: 0.6049 - top_k_categorical_accuracy: 0.8984 - val_loss: 1.7929 - val_accuracy: 0.5920 - val_top_k_categorical_accuracy: 0.8940\n",
      "Epoch 41/117\n",
      " - 1s - loss: 1.4692 - accuracy: 0.6048 - top_k_categorical_accuracy: 0.8972 - val_loss: 1.8249 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8900\n",
      "Epoch 42/117\n",
      " - 1s - loss: 1.4740 - accuracy: 0.6020 - top_k_categorical_accuracy: 0.8984 - val_loss: 1.7981 - val_accuracy: 0.5910 - val_top_k_categorical_accuracy: 0.8900\n",
      "Epoch 43/117\n",
      " - 1s - loss: 1.4633 - accuracy: 0.6049 - top_k_categorical_accuracy: 0.8984 - val_loss: 1.8073 - val_accuracy: 0.5830 - val_top_k_categorical_accuracy: 0.8920\n",
      "Epoch 44/117\n",
      " - 1s - loss: 1.4642 - accuracy: 0.6020 - top_k_categorical_accuracy: 0.8989 - val_loss: 1.8346 - val_accuracy: 0.5890 - val_top_k_categorical_accuracy: 0.8900\n",
      "Epoch 45/117\n",
      " - 1s - loss: 1.4704 - accuracy: 0.6035 - top_k_categorical_accuracy: 0.8969 - val_loss: 1.7661 - val_accuracy: 0.5930 - val_top_k_categorical_accuracy: 0.8910\n",
      "Epoch 46/117\n",
      " - 2s - loss: 1.4675 - accuracy: 0.6052 - top_k_categorical_accuracy: 0.8993 - val_loss: 1.7761 - val_accuracy: 0.5900 - val_top_k_categorical_accuracy: 0.8830\n",
      "Epoch 47/117\n",
      " - 2s - loss: 1.4635 - accuracy: 0.6019 - top_k_categorical_accuracy: 0.8984 - val_loss: 1.7656 - val_accuracy: 0.5930 - val_top_k_categorical_accuracy: 0.8840\n",
      "Epoch 48/117\n",
      " - 1s - loss: 1.4688 - accuracy: 0.6052 - top_k_categorical_accuracy: 0.8953 - val_loss: 1.7715 - val_accuracy: 0.5900 - val_top_k_categorical_accuracy: 0.8840\n",
      "Epoch 49/117\n",
      " - 1s - loss: 1.4500 - accuracy: 0.6053 - top_k_categorical_accuracy: 0.8984 - val_loss: 1.7637 - val_accuracy: 0.5920 - val_top_k_categorical_accuracy: 0.8860\n",
      "Epoch 50/117\n",
      " - 1s - loss: 1.4656 - accuracy: 0.6028 - top_k_categorical_accuracy: 0.8965 - val_loss: 1.7467 - val_accuracy: 0.5940 - val_top_k_categorical_accuracy: 0.8880\n",
      "Epoch 51/117\n",
      " - 2s - loss: 1.4622 - accuracy: 0.5981 - top_k_categorical_accuracy: 0.9013 - val_loss: 1.7470 - val_accuracy: 0.5940 - val_top_k_categorical_accuracy: 0.8870\n",
      "Epoch 52/117\n",
      " - 2s - loss: 1.4570 - accuracy: 0.6067 - top_k_categorical_accuracy: 0.8989 - val_loss: 1.7496 - val_accuracy: 0.5910 - val_top_k_categorical_accuracy: 0.8850\n",
      "Epoch 53/117\n",
      " - 2s - loss: 1.4616 - accuracy: 0.6037 - top_k_categorical_accuracy: 0.9008 - val_loss: 1.7357 - val_accuracy: 0.5870 - val_top_k_categorical_accuracy: 0.8900\n",
      "Epoch 54/117\n",
      " - 2s - loss: 1.4576 - accuracy: 0.6039 - top_k_categorical_accuracy: 0.9003 - val_loss: 1.7411 - val_accuracy: 0.5930 - val_top_k_categorical_accuracy: 0.8890\n",
      "Epoch 55/117\n",
      " - 1s - loss: 1.4594 - accuracy: 0.6080 - top_k_categorical_accuracy: 0.8965 - val_loss: 1.7307 - val_accuracy: 0.5930 - val_top_k_categorical_accuracy: 0.8910\n",
      "Epoch 56/117\n",
      " - 2s - loss: 1.4557 - accuracy: 0.6029 - top_k_categorical_accuracy: 0.8996 - val_loss: 1.7268 - val_accuracy: 0.5940 - val_top_k_categorical_accuracy: 0.8880\n",
      "Epoch 57/117\n",
      " - 2s - loss: 1.4546 - accuracy: 0.6031 - top_k_categorical_accuracy: 0.8992 - val_loss: 1.7461 - val_accuracy: 0.5910 - val_top_k_categorical_accuracy: 0.8860\n",
      "Epoch 58/117\n",
      " - 1s - loss: 1.4550 - accuracy: 0.6033 - top_k_categorical_accuracy: 0.8995 - val_loss: 1.7240 - val_accuracy: 0.5920 - val_top_k_categorical_accuracy: 0.8890\n",
      "Epoch 59/117\n",
      " - 1s - loss: 1.4530 - accuracy: 0.6049 - top_k_categorical_accuracy: 0.9043 - val_loss: 1.7220 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8900\n",
      "Epoch 60/117\n",
      " - 1s - loss: 1.4589 - accuracy: 0.6035 - top_k_categorical_accuracy: 0.8949 - val_loss: 1.7245 - val_accuracy: 0.5890 - val_top_k_categorical_accuracy: 0.8900\n",
      "Epoch 61/117\n",
      " - 1s - loss: 1.4551 - accuracy: 0.6012 - top_k_categorical_accuracy: 0.9000 - val_loss: 1.7285 - val_accuracy: 0.5900 - val_top_k_categorical_accuracy: 0.8840\n",
      "Epoch 62/117\n",
      " - 2s - loss: 1.4609 - accuracy: 0.6017 - top_k_categorical_accuracy: 0.8967 - val_loss: 1.7182 - val_accuracy: 0.5900 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 63/117\n",
      " - 2s - loss: 1.4508 - accuracy: 0.6028 - top_k_categorical_accuracy: 0.8979 - val_loss: 1.7307 - val_accuracy: 0.5880 - val_top_k_categorical_accuracy: 0.8850\n",
      "Epoch 64/117\n",
      " - 2s - loss: 1.4536 - accuracy: 0.6065 - top_k_categorical_accuracy: 0.9000 - val_loss: 1.7248 - val_accuracy: 0.5870 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 65/117\n",
      " - 2s - loss: 1.4369 - accuracy: 0.6045 - top_k_categorical_accuracy: 0.9023 - val_loss: 1.7239 - val_accuracy: 0.5900 - val_top_k_categorical_accuracy: 0.8830\n",
      "Epoch 66/117\n",
      " - 1s - loss: 1.4401 - accuracy: 0.6077 - top_k_categorical_accuracy: 0.9000 - val_loss: 1.7309 - val_accuracy: 0.5890 - val_top_k_categorical_accuracy: 0.8810\n",
      "Epoch 67/117\n",
      " - 1s - loss: 1.4472 - accuracy: 0.6085 - top_k_categorical_accuracy: 0.9005 - val_loss: 1.7273 - val_accuracy: 0.5870 - val_top_k_categorical_accuracy: 0.8800\n",
      "Epoch 68/117\n",
      " - 2s - loss: 1.4437 - accuracy: 0.6056 - top_k_categorical_accuracy: 0.9001 - val_loss: 1.7206 - val_accuracy: 0.5900 - val_top_k_categorical_accuracy: 0.8790\n",
      "Epoch 69/117\n",
      " - 1s - loss: 1.4402 - accuracy: 0.6071 - top_k_categorical_accuracy: 0.8988 - val_loss: 1.7245 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8810\n",
      "Epoch 70/117\n",
      " - 1s - loss: 1.4403 - accuracy: 0.6035 - top_k_categorical_accuracy: 0.9019 - val_loss: 1.7220 - val_accuracy: 0.5900 - val_top_k_categorical_accuracy: 0.8770\n",
      "Epoch 71/117\n",
      " - 1s - loss: 1.4462 - accuracy: 0.6073 - top_k_categorical_accuracy: 0.8979 - val_loss: 1.7431 - val_accuracy: 0.5860 - val_top_k_categorical_accuracy: 0.8790\n",
      "Epoch 72/117\n",
      " - 1s - loss: 1.4435 - accuracy: 0.6069 - top_k_categorical_accuracy: 0.8988 - val_loss: 1.7404 - val_accuracy: 0.5880 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 73/117\n",
      " - 1s - loss: 1.4554 - accuracy: 0.6069 - top_k_categorical_accuracy: 0.8975 - val_loss: 1.7218 - val_accuracy: 0.5890 - val_top_k_categorical_accuracy: 0.8730\n",
      "Epoch 74/117\n",
      " - 1s - loss: 1.4509 - accuracy: 0.6008 - top_k_categorical_accuracy: 0.9028 - val_loss: 1.7293 - val_accuracy: 0.5890 - val_top_k_categorical_accuracy: 0.8780\n",
      "Epoch 75/117\n",
      " - 2s - loss: 1.4447 - accuracy: 0.6069 - top_k_categorical_accuracy: 0.9033 - val_loss: 1.7231 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8790\n",
      "Epoch 76/117\n",
      " - 1s - loss: 1.4464 - accuracy: 0.6044 - top_k_categorical_accuracy: 0.9013 - val_loss: 1.7231 - val_accuracy: 0.5880 - val_top_k_categorical_accuracy: 0.8780\n",
      "Epoch 77/117\n",
      " - 2s - loss: 1.4483 - accuracy: 0.6029 - top_k_categorical_accuracy: 0.9013 - val_loss: 1.7120 - val_accuracy: 0.5890 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 78/117\n",
      " - 1s - loss: 1.4454 - accuracy: 0.6048 - top_k_categorical_accuracy: 0.8984 - val_loss: 1.7246 - val_accuracy: 0.5910 - val_top_k_categorical_accuracy: 0.8850\n",
      "Epoch 79/117\n",
      " - 1s - loss: 1.4456 - accuracy: 0.6049 - top_k_categorical_accuracy: 0.9036 - val_loss: 1.7382 - val_accuracy: 0.5860 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 80/117\n",
      " - 2s - loss: 1.4433 - accuracy: 0.6045 - top_k_categorical_accuracy: 0.8992 - val_loss: 1.7214 - val_accuracy: 0.5890 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 81/117\n",
      " - 1s - loss: 1.4364 - accuracy: 0.6064 - top_k_categorical_accuracy: 0.9017 - val_loss: 1.7401 - val_accuracy: 0.5870 - val_top_k_categorical_accuracy: 0.8830\n",
      "Epoch 82/117\n",
      " - 2s - loss: 1.4377 - accuracy: 0.6116 - top_k_categorical_accuracy: 0.9009 - val_loss: 1.7249 - val_accuracy: 0.5920 - val_top_k_categorical_accuracy: 0.8800\n",
      "Epoch 83/117\n",
      " - 2s - loss: 1.4457 - accuracy: 0.6089 - top_k_categorical_accuracy: 0.9008 - val_loss: 1.7154 - val_accuracy: 0.5880 - val_top_k_categorical_accuracy: 0.8810\n",
      "Epoch 84/117\n",
      " - 1s - loss: 1.4375 - accuracy: 0.6071 - top_k_categorical_accuracy: 0.9049 - val_loss: 1.7116 - val_accuracy: 0.5880 - val_top_k_categorical_accuracy: 0.8790\n",
      "Epoch 85/117\n",
      " - 1s - loss: 1.4344 - accuracy: 0.6043 - top_k_categorical_accuracy: 0.9009 - val_loss: 1.7098 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8830\n",
      "Epoch 86/117\n",
      " - 1s - loss: 1.4455 - accuracy: 0.6053 - top_k_categorical_accuracy: 0.8992 - val_loss: 1.7113 - val_accuracy: 0.5860 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 87/117\n",
      " - 1s - loss: 1.4385 - accuracy: 0.6051 - top_k_categorical_accuracy: 0.9009 - val_loss: 1.7008 - val_accuracy: 0.5860 - val_top_k_categorical_accuracy: 0.8810\n",
      "Epoch 88/117\n",
      " - 1s - loss: 1.4322 - accuracy: 0.6060 - top_k_categorical_accuracy: 0.8984 - val_loss: 1.7029 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 89/117\n",
      " - 1s - loss: 1.4338 - accuracy: 0.6073 - top_k_categorical_accuracy: 0.9041 - val_loss: 1.7097 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 90/117\n",
      " - 2s - loss: 1.4402 - accuracy: 0.6081 - top_k_categorical_accuracy: 0.9004 - val_loss: 1.6933 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 91/117\n",
      " - 1s - loss: 1.4438 - accuracy: 0.6037 - top_k_categorical_accuracy: 0.9025 - val_loss: 1.7101 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8830\n",
      "Epoch 92/117\n",
      " - 1s - loss: 1.4351 - accuracy: 0.6079 - top_k_categorical_accuracy: 0.8959 - val_loss: 1.6897 - val_accuracy: 0.5830 - val_top_k_categorical_accuracy: 0.8860\n",
      "Epoch 93/117\n",
      " - 1s - loss: 1.4316 - accuracy: 0.6077 - top_k_categorical_accuracy: 0.9009 - val_loss: 1.7251 - val_accuracy: 0.5820 - val_top_k_categorical_accuracy: 0.8840\n",
      "Epoch 94/117\n",
      " - 1s - loss: 1.4319 - accuracy: 0.6015 - top_k_categorical_accuracy: 0.9000 - val_loss: 1.7244 - val_accuracy: 0.5810 - val_top_k_categorical_accuracy: 0.8880\n",
      "Epoch 95/117\n",
      " - 2s - loss: 1.4309 - accuracy: 0.6061 - top_k_categorical_accuracy: 0.9011 - val_loss: 1.7230 - val_accuracy: 0.5820 - val_top_k_categorical_accuracy: 0.8810\n",
      "Epoch 96/117\n",
      " - 1s - loss: 1.4400 - accuracy: 0.6061 - top_k_categorical_accuracy: 0.8985 - val_loss: 1.7212 - val_accuracy: 0.5830 - val_top_k_categorical_accuracy: 0.8800\n",
      "Epoch 97/117\n",
      " - 1s - loss: 1.4335 - accuracy: 0.6079 - top_k_categorical_accuracy: 0.9003 - val_loss: 1.7127 - val_accuracy: 0.5810 - val_top_k_categorical_accuracy: 0.8790\n",
      "Epoch 98/117\n",
      " - 1s - loss: 1.4407 - accuracy: 0.6044 - top_k_categorical_accuracy: 0.8988 - val_loss: 1.7063 - val_accuracy: 0.5840 - val_top_k_categorical_accuracy: 0.8760\n",
      "Epoch 99/117\n",
      " - 1s - loss: 1.4272 - accuracy: 0.6057 - top_k_categorical_accuracy: 0.9028 - val_loss: 1.7207 - val_accuracy: 0.5790 - val_top_k_categorical_accuracy: 0.8800\n",
      "Epoch 100/117\n",
      " - 1s - loss: 1.4310 - accuracy: 0.6084 - top_k_categorical_accuracy: 0.8984 - val_loss: 1.7254 - val_accuracy: 0.5770 - val_top_k_categorical_accuracy: 0.8800\n",
      "Epoch 101/117\n",
      " - 1s - loss: 1.4337 - accuracy: 0.6055 - top_k_categorical_accuracy: 0.9024 - val_loss: 1.7368 - val_accuracy: 0.5800 - val_top_k_categorical_accuracy: 0.8770\n",
      "Epoch 102/117\n",
      " - 1s - loss: 1.4303 - accuracy: 0.6053 - top_k_categorical_accuracy: 0.9041 - val_loss: 1.7214 - val_accuracy: 0.5850 - val_top_k_categorical_accuracy: 0.8780\n",
      "Epoch 103/117\n",
      " - 1s - loss: 1.4336 - accuracy: 0.6079 - top_k_categorical_accuracy: 0.9003 - val_loss: 1.7073 - val_accuracy: 0.5810 - val_top_k_categorical_accuracy: 0.8800\n",
      "Epoch 104/117\n",
      " - 1s - loss: 1.4378 - accuracy: 0.6061 - top_k_categorical_accuracy: 0.9015 - val_loss: 1.7011 - val_accuracy: 0.5800 - val_top_k_categorical_accuracy: 0.8800\n",
      "Epoch 105/117\n",
      " - 1s - loss: 1.4270 - accuracy: 0.6060 - top_k_categorical_accuracy: 0.9021 - val_loss: 1.7144 - val_accuracy: 0.5830 - val_top_k_categorical_accuracy: 0.8810\n",
      "Epoch 106/117\n",
      " - 1s - loss: 1.4283 - accuracy: 0.6064 - top_k_categorical_accuracy: 0.9008 - val_loss: 1.7066 - val_accuracy: 0.5810 - val_top_k_categorical_accuracy: 0.8780\n",
      "Epoch 107/117\n",
      " - 1s - loss: 1.4210 - accuracy: 0.6101 - top_k_categorical_accuracy: 0.9004 - val_loss: 1.7149 - val_accuracy: 0.5740 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 108/117\n",
      " - 2s - loss: 1.4297 - accuracy: 0.6064 - top_k_categorical_accuracy: 0.9003 - val_loss: 1.7255 - val_accuracy: 0.5780 - val_top_k_categorical_accuracy: 0.8820\n",
      "Epoch 109/117\n",
      " - 2s - loss: 1.4318 - accuracy: 0.6045 - top_k_categorical_accuracy: 0.9037 - val_loss: 1.7263 - val_accuracy: 0.5810 - val_top_k_categorical_accuracy: 0.8830\n",
      "Epoch 110/117\n",
      " - 2s - loss: 1.4271 - accuracy: 0.6056 - top_k_categorical_accuracy: 0.9019 - val_loss: 1.7224 - val_accuracy: 0.5830 - val_top_k_categorical_accuracy: 0.8830\n",
      "Epoch 111/117\n",
      " - 2s - loss: 1.4310 - accuracy: 0.6069 - top_k_categorical_accuracy: 0.9005 - val_loss: 1.7330 - val_accuracy: 0.5800 - val_top_k_categorical_accuracy: 0.8750\n",
      "Epoch 112/117\n",
      " - 2s - loss: 1.4292 - accuracy: 0.6073 - top_k_categorical_accuracy: 0.9024 - val_loss: 1.7573 - val_accuracy: 0.5770 - val_top_k_categorical_accuracy: 0.8840\n",
      "Epoch 113/117\n",
      " - 2s - loss: 1.4284 - accuracy: 0.6104 - top_k_categorical_accuracy: 0.9032 - val_loss: 1.7533 - val_accuracy: 0.5790 - val_top_k_categorical_accuracy: 0.8750\n",
      "Epoch 114/117\n",
      " - 1s - loss: 1.4307 - accuracy: 0.6051 - top_k_categorical_accuracy: 0.9028 - val_loss: 1.7345 - val_accuracy: 0.5820 - val_top_k_categorical_accuracy: 0.8760\n",
      "Epoch 115/117\n",
      " - 1s - loss: 1.4307 - accuracy: 0.6091 - top_k_categorical_accuracy: 0.9016 - val_loss: 1.7209 - val_accuracy: 0.5790 - val_top_k_categorical_accuracy: 0.8790\n",
      "Epoch 116/117\n",
      " - 2s - loss: 1.4325 - accuracy: 0.6045 - top_k_categorical_accuracy: 0.9028 - val_loss: 1.7257 - val_accuracy: 0.5760 - val_top_k_categorical_accuracy: 0.8810\n",
      "Epoch 117/117\n",
      " - 2s - loss: 1.4227 - accuracy: 0.6091 - top_k_categorical_accuracy: 0.9025 - val_loss: 1.7312 - val_accuracy: 0.5810 - val_top_k_categorical_accuracy: 0.8830\n",
      "1000/1000 [==============================] - 0s 83us/step\n",
      "[1.7311692128181457, 0.5809999704360962, 0.8830000162124634]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DR_NN_input=np.zeros([N_Split_train*N_delt,2*output_dim])\n",
    "DR_NN_input[:,0:output_dim]=P_DNN\n",
    "DR_NN_input[:,output_dim:2*output_dim]=P_RNN\n",
    "print(N_Split_train*N_delt)\n",
    "DR_NN_input=np.loadtxt(\"DR_NN_input_30_250.txt\",delimiter=\",\")\n",
    "G_NN=np.loadtxt(\"./G_NN_30_250.txt\",delimiter=\",\")\n",
    "\n",
    "DR_NN_test=np.zeros([N_Split,2*output_dim])\n",
    "DR_NN_test[:,0:output_dim]=P_DNN_test\n",
    "DR_NN_test[:,output_dim:2*output_dim]=P_RNN_test\n",
    "print(N_Split)\n",
    "\n",
    "N_BATCH=32\n",
    "dp=0.9\n",
    "RD_model = Sequential()\n",
    "RD_model.add(Dense(128,input_dim=output_dim*2))\n",
    "RD_model.add(BatchNormalization())\n",
    "RD_model.add(PReLU())\n",
    "RD_model.add(Dropout(dp))\n",
    "\n",
    "RD_model.add(Dense(output_dim))\n",
    "RD_model.add(Activation('softmax'))\n",
    "RD_model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', metrics.top_k_categorical_accuracy])\n",
    "RD_model.summary()\n",
    "fittingDR=RD_model.fit(DR_NN_input, G_NN, epochs=117, batch_size=N_BATCH,verbose=2,validation_data=(DR_NN_test,G_NN_test),shuffle=True)\n",
    "# RD_model.save('jjs_model_0307R_D_V1.h5')\n",
    "# RD_model=load_model('jjs_model_0307R_D_V1.h5')\n",
    "score_DR=RD_model.evaluate(DR_NN_test, G_NN_test,verbose=1)  \n",
    "print(score_DR)\n",
    "\n",
    "\n",
    "loss = fittingDR.history['loss']\n",
    "val_loss = fittingDR.history['val_loss']\n",
    "epochs = range(len(loss))\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'ro', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.grid() \n",
    "plt.savefig('./Batc64HN128_64_Ep30_LOSS.png')\n",
    "plt.show()\n",
    "\n",
    "top_acc_train=fittingDR.history['accuracy']\n",
    "top_acc=fittingDR.history['val_accuracy']\n",
    "epochs = range(len(loss))\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(epochs, top_acc_train, 'bo', label='Train top acc')\n",
    "plt.plot(epochs, top_acc, 'ro', label='Val top acc')\n",
    "plt.title('Training and validation ACC')\n",
    "plt.legend()\n",
    "plt.grid() \n",
    "plt.savefig('./Batc64HN128_64_Ep30_ACC.png')\n",
    "plt.show()\n",
    "\n",
    "top5_acc_train=fittingDR.history['top_k_categorical_accuracy']\n",
    "top5_acc=fittingDR.history['val_top_k_categorical_accuracy']\n",
    "epochs = range(len(loss))\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(epochs, top5_acc_train, 'bo', label='Train top 5 acc')\n",
    "plt.plot(epochs, top5_acc, 'ro', label='Val top 5 acc')\n",
    "plt.title('Training and validation TOP5_ACC')\n",
    "plt.legend()\n",
    "plt.grid() \n",
    "plt.savefig('./Batc64HN128_64_Ep30_TOP5ACC.png')\n",
    "plt.show()\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"DR_NN_test.txt\", DR_NN_test,fmt='%f',delimiter=',')\n",
    "np.savetxt(\"DR_NN_input.txt\", DR_NN_input,fmt='%f',delimiter=',')\n",
    "np.savetxt(\"G_NN.txt\", G_NN,fmt='%f',delimiter=',')\n",
    "np.savetxt(\"G_NN_test.txt\", DR_NN_input,fmt='%f',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"ACC0211.txt\", ACC,fmt='%f',delimiter=',')\n",
    "P_DNN=np.zeros([N_Split,labelsArrayOverSampler_1hot.shape[-1]])\n",
    "P_RNN=np.zeros([N_Split,labelsArrayOverSampler_1hot.shape[-1]])\n",
    "G_NN =np.zeros([N_Split,labelsArrayOverSampler_1hot.shape[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TR1:steps_per_epoch=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.88671302, 0.09      , 0.659     ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_2,axis=0)#有误，不知道为什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generator at 0x7ff205d838e0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
    "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "begin from 0206 23:35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaaaa=np.mean(ACC,axis=0)\n",
    "aaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "a=[[0,0,1,0]]\n",
    "b=[[1,0,0,0]]\n",
    "c=[[1,0,0,0]]\n",
    "rr=np.sum(np.abs(np.array(a)-np.array(b)))\n",
    "print(rr)\n",
    "ss=np.sum(np.abs(np.array(c)-np.array(b)))\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
